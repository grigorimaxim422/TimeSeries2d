{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb104376-e5cd-4ce0-beda-0e62b9ab2c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-01-13 19:57:41,670] A new study created in memory with name: no-name-1f040c11-89a2-4c6e-b1bc-8723313540b7\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15248\\354736787.py:80: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2025-01-13 19:58:00,129] Trial 0 finished with value: 0.0001310570468459363 and parameters: {'hidden_dim': 32, 'num_layers': 2, 'dropout': 0.45990841448275077, 'learning_rate': 0.003344865476755948}. Best is trial 0 with value: 0.0001310570468459363.\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15248\\354736787.py:80: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.22620320743383304 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 19:58:17,272] Trial 1 finished with value: 0.0002218037724643099 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.22620320743383304, 'learning_rate': 0.00729474683811613}. Best is trial 0 with value: 0.0001310570468459363.\n",
      "[I 2025-01-13 19:58:36,019] Trial 2 finished with value: 8.865044632826043e-05 and parameters: {'hidden_dim': 32, 'num_layers': 2, 'dropout': 0.3298409886654472, 'learning_rate': 0.000491778417934524}. Best is trial 2 with value: 8.865044632826043e-05.\n",
      "[I 2025-01-13 19:59:44,702] Trial 3 finished with value: 9.41882244660519e-05 and parameters: {'hidden_dim': 160, 'num_layers': 3, 'dropout': 0.2883618479681237, 'learning_rate': 0.00021540344950295122}. Best is trial 2 with value: 8.865044632826043e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2130919237863096 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:00:12,521] Trial 4 finished with value: 5.898866137696049e-05 and parameters: {'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.2130919237863096, 'learning_rate': 0.00043757169383258203}. Best is trial 4 with value: 5.898866137696049e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4510006056690541 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:00:34,042] Trial 5 finished with value: 6.088649686055512e-05 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.4510006056690541, 'learning_rate': 0.00202057895708676}. Best is trial 4 with value: 5.898866137696049e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23430907073769747 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:00:44,036] Trial 6 finished with value: 5.237681596719829e-05 and parameters: {'hidden_dim': 32, 'num_layers': 1, 'dropout': 0.23430907073769747, 'learning_rate': 0.001066585980871364}. Best is trial 6 with value: 5.237681596719829e-05.\n",
      "[I 2025-01-13 20:01:02,230] Trial 7 finished with value: 9.260326160901141e-05 and parameters: {'hidden_dim': 32, 'num_layers': 2, 'dropout': 0.141041761145272, 'learning_rate': 0.0009140273185049934}. Best is trial 6 with value: 5.237681596719829e-05.\n",
      "[I 2025-01-13 20:02:56,583] Trial 8 finished with value: 0.0001523626937837848 and parameters: {'hidden_dim': 224, 'num_layers': 4, 'dropout': 0.3427649508289206, 'learning_rate': 0.0007719957658638127}. Best is trial 6 with value: 5.237681596719829e-05.\n",
      "[I 2025-01-13 20:03:49,071] Trial 9 finished with value: 0.00014951780626275152 and parameters: {'hidden_dim': 96, 'num_layers': 3, 'dropout': 0.377637730136381, 'learning_rate': 0.000283946314515763}. Best is trial 6 with value: 5.237681596719829e-05.\n",
      "[I 2025-01-13 20:05:35,243] Trial 10 finished with value: 0.00012461380075282332 and parameters: {'hidden_dim': 192, 'num_layers': 4, 'dropout': 0.11833283156102951, 'learning_rate': 0.0001336116059911818}. Best is trial 6 with value: 5.237681596719829e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2292606768030479 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:06:04,091] Trial 11 finished with value: 5.149645767232869e-05 and parameters: {'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.2292606768030479, 'learning_rate': 0.0021479920806251754}. Best is trial 11 with value: 5.149645767232869e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.22399218903253293 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:06:32,284] Trial 12 finished with value: 7.138358308690262e-05 and parameters: {'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.22399218903253293, 'learning_rate': 0.0020557360749884016}. Best is trial 11 with value: 5.149645767232869e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.26173712607330896 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:06:49,923] Trial 13 finished with value: 5.3013059600330465e-05 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.26173712607330896, 'learning_rate': 0.0017636360212106557}. Best is trial 11 with value: 5.149645767232869e-05.\n",
      "[I 2025-01-13 20:07:40,598] Trial 14 finished with value: 8.707597358311018e-05 and parameters: {'hidden_dim': 192, 'num_layers': 2, 'dropout': 0.18373324840059185, 'learning_rate': 0.004899756763146294}. Best is trial 11 with value: 5.149645767232869e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.16097944159993013 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:07:55,734] Trial 15 finished with value: 5.652161896498662e-05 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.16097944159993013, 'learning_rate': 0.0014364264373876885}. Best is trial 11 with value: 5.149645767232869e-05.\n",
      "[I 2025-01-13 20:09:05,192] Trial 16 finished with value: 0.0010307999327778816 and parameters: {'hidden_dim': 160, 'num_layers': 3, 'dropout': 0.2719458640499871, 'learning_rate': 0.0035414126901087426}. Best is trial 11 with value: 5.149645767232869e-05.\n",
      "[I 2025-01-13 20:10:00,400] Trial 17 finished with value: 7.899549415345642e-05 and parameters: {'hidden_dim': 224, 'num_layers': 2, 'dropout': 0.4075848582758745, 'learning_rate': 0.008540979654776907}. Best is trial 11 with value: 5.149645767232869e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1945420317498053 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:10:22,135] Trial 18 finished with value: 9.755926227874376e-05 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.1945420317498053, 'learning_rate': 0.00065082976114919}. Best is trial 11 with value: 5.149645767232869e-05.\n",
      "[I 2025-01-13 20:10:53,475] Trial 19 finished with value: 0.00021639695809095758 and parameters: {'hidden_dim': 64, 'num_layers': 2, 'dropout': 0.10034885267694652, 'learning_rate': 0.0013343537245191761}. Best is trial 11 with value: 5.149645767232869e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.327002134891361 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:11:17,472] Trial 20 finished with value: 5.8503291504828006e-05 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.327002134891361, 'learning_rate': 0.0031608363387416716}. Best is trial 11 with value: 5.149645767232869e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25514762742524016 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:11:34,735] Trial 21 finished with value: 5.048279275466815e-05 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.25514762742524016, 'learning_rate': 0.0018681870589779695}. Best is trial 21 with value: 5.048279275466815e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25151008227077704 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:11:49,716] Trial 22 finished with value: 5.483924624885813e-05 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.25151008227077704, 'learning_rate': 0.001208593516490223}. Best is trial 21 with value: 5.048279275466815e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.30883575663821067 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:12:04,782] Trial 23 finished with value: 4.812329544537616e-05 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.30883575663821067, 'learning_rate': 0.0026030491965989343}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "[I 2025-01-13 20:12:41,846] Trial 24 finished with value: 0.00018980125605594367 and parameters: {'hidden_dim': 96, 'num_layers': 2, 'dropout': 0.2996705231630229, 'learning_rate': 0.005079477807591742}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.37855672398652884 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:13:03,103] Trial 25 finished with value: 7.34393156149467e-05 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.37855672398652884, 'learning_rate': 0.002677473786533505}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "[I 2025-01-13 20:13:33,719] Trial 26 finished with value: 0.00014653016180752522 and parameters: {'hidden_dim': 64, 'num_layers': 2, 'dropout': 0.3052948745095649, 'learning_rate': 0.005137242529776699}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3564529515548894 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:13:56,394] Trial 27 finished with value: 0.0001596050688848746 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.3564529515548894, 'learning_rate': 0.0024203689357241843}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "[I 2025-01-13 20:14:51,595] Trial 28 finished with value: 0.00011766573086126961 and parameters: {'hidden_dim': 96, 'num_layers': 3, 'dropout': 0.18334840194748783, 'learning_rate': 0.0016505304152418649}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4188525143020128 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:15:17,076] Trial 29 finished with value: 0.00010353535154453394 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.4188525143020128, 'learning_rate': 0.004031332509163212}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "[I 2025-01-13 20:15:48,980] Trial 30 finished with value: 0.0002659011727452955 and parameters: {'hidden_dim': 64, 'num_layers': 2, 'dropout': 0.27463451105972986, 'learning_rate': 0.006623640825384413}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2475533312387332 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:16:00,060] Trial 31 finished with value: 6.569277634711894e-05 and parameters: {'hidden_dim': 32, 'num_layers': 1, 'dropout': 0.2475533312387332, 'learning_rate': 0.0010084687107992745}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23733745495772862 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:16:10,852] Trial 32 finished with value: 5.326151949702762e-05 and parameters: {'hidden_dim': 32, 'num_layers': 1, 'dropout': 0.23733745495772862, 'learning_rate': 0.0025284053893733036}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.31672749047000565 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:16:20,928] Trial 33 finished with value: 6.886405555467883e-05 and parameters: {'hidden_dim': 32, 'num_layers': 1, 'dropout': 0.31672749047000565, 'learning_rate': 0.0005335855139515358}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20558034136424186 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:16:35,193] Trial 34 finished with value: 5.178010509222407e-05 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.20558034136424186, 'learning_rate': 0.0010961213480842461}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "[I 2025-01-13 20:17:10,624] Trial 35 finished with value: 0.00013524728737221184 and parameters: {'hidden_dim': 96, 'num_layers': 2, 'dropout': 0.21306050414631017, 'learning_rate': 0.0014915571350752892}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.27990574735276447 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:17:24,878] Trial 36 finished with value: 5.807358188163066e-05 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.27990574735276447, 'learning_rate': 0.0003893071374989754}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "[I 2025-01-13 20:18:08,510] Trial 37 finished with value: 0.0001890798594104126 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.162615051472876, 'learning_rate': 0.002111001765506296}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2089645874323363 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:18:25,381] Trial 38 finished with value: 5.5720092528975904e-05 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.2089645874323363, 'learning_rate': 0.0008474536530453197}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.29824916336862556 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:18:54,296] Trial 39 finished with value: 6.564078384227204e-05 and parameters: {'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.29824916336862556, 'learning_rate': 0.0030386619475738746}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.17084063824320053 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:19:09,200] Trial 40 finished with value: 5.2269706264434553e-05 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.17084063824320053, 'learning_rate': 0.001128305325122148}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.16017529893637675 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:19:23,412] Trial 41 finished with value: 6.509212901371278e-05 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.16017529893637675, 'learning_rate': 0.0006995892732976059}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.13878757207739542 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:19:38,081] Trial 42 finished with value: 4.995539695135614e-05 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.13878757207739542, 'learning_rate': 0.0011654388801722695}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.13786248513038266 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:19:48,907] Trial 43 finished with value: 0.00012594879411732438 and parameters: {'hidden_dim': 32, 'num_layers': 1, 'dropout': 0.13786248513038266, 'learning_rate': 0.0022377405760468034}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1378237223975316 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:20:05,779] Trial 44 finished with value: 8.054137486562303e-05 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.1378237223975316, 'learning_rate': 0.0017028998268532906}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.22643526599367883 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:20:26,745] Trial 45 finished with value: 6.735500871648334e-05 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.22643526599367883, 'learning_rate': 0.0009279265596381729}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20573784988768298 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:20:43,680] Trial 46 finished with value: 7.300879951799288e-05 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.20573784988768298, 'learning_rate': 0.0018886409265246424}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "[I 2025-01-13 20:21:45,581] Trial 47 finished with value: 0.00014902838004424913 and parameters: {'hidden_dim': 64, 'num_layers': 4, 'dropout': 0.49144681956050296, 'learning_rate': 0.003938781259773873}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "[I 2025-01-13 20:22:04,565] Trial 48 finished with value: 0.0008056023216340691 and parameters: {'hidden_dim': 32, 'num_layers': 2, 'dropout': 0.2579255926392612, 'learning_rate': 0.00010365550136065446}. Best is trial 23 with value: 4.812329544537616e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2306544454200878 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:22:18,235] Trial 49 finished with value: 4.870175375386184e-05 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.2306544454200878, 'learning_rate': 0.0013793666986234325}. Best is trial 23 with value: 4.812329544537616e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.30883575663821067, 'learning_rate': 0.0026030491965989343}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv(\"Book1.csv\")\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "data = data.sort_values(by=\"Date\")\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "numeric_data = data.drop(columns=[\"Date\"])\n",
    "scaled_data = scaler.fit_transform(numeric_data)\n",
    "data[numeric_data.columns] = scaled_data\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_data = data[(data[\"Date\"].dt.year >= 2017) & (data[\"Date\"].dt.year <= 2022)].drop(columns=[\"Date\"]).values\n",
    "val_data = data[data[\"Date\"].dt.year == 2023].drop(columns=[\"Date\"]).values\n",
    "test_data = data[data[\"Date\"].dt.year == 2024].drop(columns=[\"Date\"]).values\n",
    "\n",
    "# Convert data to sequences for time series\n",
    "def create_sequences(data, sequence_length=30):\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequences.append(data[i:i + sequence_length])\n",
    "        targets.append(data[i + sequence_length, 0])  # Assuming target is the first column\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "sequence_length = 30\n",
    "X_train, y_train = create_sequences(train_data, sequence_length)\n",
    "X_val, y_val = create_sequences(val_data, sequence_length)\n",
    "X_test, y_test = create_sequences(test_data, sequence_length)\n",
    "\n",
    "# Prepare data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                        torch.tensor(y_train, dtype=torch.float32)), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                                      torch.tensor(y_val, dtype=torch.float32)), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.MSELoss()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            predictions = model(X_batch).squeeze()\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Define the GRU model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gru_out, _ = self.gru(x)\n",
    "        return self.fc(gru_out[:, -1, :])\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 32, 256, step=32)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
    "    num_epochs = 20\n",
    "\n",
    "    # Initialize model\n",
    "    model = GRUModel(X_train.shape[2], hidden_dim, num_layers, dropout)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Training setup\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(X_batch).squeeze()\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate on validation data\n",
    "    val_loss = evaluate_model(model, val_loader, device)\n",
    "    return val_loss\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Output the best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f608059-3d52-43a1-8554-08b71c12796b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
