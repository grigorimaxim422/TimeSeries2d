{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "951856d6-6190-44e3-9235-f0ca5dec6058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-01-13 20:31:57,632] A new study created in memory with name: no-name-4c097df4-3934-41e3-bb4a-f37d3ebc3479\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14812\\237558714.py:84: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2025-01-13 20:33:16,479] Trial 0 finished with value: 0.0005824000757208771 and parameters: {'hidden_dim': 192, 'num_layers': 3, 'dropout': 0.12615910117049609, 'learning_rate': 0.00012131949519588089}. Best is trial 0 with value: 0.0005824000757208771.\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14812\\237558714.py:84: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.26364259414865154 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:33:32,265] Trial 1 finished with value: 0.001334355035479265 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.26364259414865154, 'learning_rate': 0.00025534828751671944}. Best is trial 0 with value: 0.0005824000757208771.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.278647460043709 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:33:55,867] Trial 2 finished with value: 0.0002530296710161069 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.278647460043709, 'learning_rate': 0.00026061021735957266}. Best is trial 2 with value: 0.0002530296710161069.\n",
      "[I 2025-01-13 20:34:47,685] Trial 3 finished with value: 0.00018433456782738423 and parameters: {'hidden_dim': 192, 'num_layers': 2, 'dropout': 0.16624089402421238, 'learning_rate': 0.005354244487411721}. Best is trial 3 with value: 0.00018433456782738423.\n",
      "[I 2025-01-13 20:35:51,563] Trial 4 finished with value: 0.0005532920291774313 and parameters: {'hidden_dim': 64, 'num_layers': 4, 'dropout': 0.2256289607190996, 'learning_rate': 0.00013069031436572498}. Best is trial 3 with value: 0.00018433456782738423.\n",
      "[I 2025-01-13 20:36:47,064] Trial 5 finished with value: 0.0002875124442983757 and parameters: {'hidden_dim': 192, 'num_layers': 2, 'dropout': 0.4744923277284997, 'learning_rate': 0.00174768982670048}. Best is trial 3 with value: 0.00018433456782738423.\n",
      "[I 2025-01-13 20:37:05,855] Trial 6 finished with value: 0.0005443597752177579 and parameters: {'hidden_dim': 32, 'num_layers': 2, 'dropout': 0.43332928247081404, 'learning_rate': 0.00017157404163949577}. Best is trial 3 with value: 0.00018433456782738423.\n",
      "[I 2025-01-13 20:38:52,722] Trial 7 finished with value: 0.00034893689470746637 and parameters: {'hidden_dim': 256, 'num_layers': 3, 'dropout': 0.1329287506566845, 'learning_rate': 0.0003148436483891221}. Best is trial 3 with value: 0.00018433456782738423.\n",
      "[I 2025-01-13 20:39:38,461] Trial 8 finished with value: 0.0004660435978704217 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.48035921740698884, 'learning_rate': 0.006288435238255973}. Best is trial 3 with value: 0.00018433456782738423.\n",
      "[I 2025-01-13 20:40:24,239] Trial 9 finished with value: 0.0002879696588603441 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.32645044189485267, 'learning_rate': 0.0002332508355823912}. Best is trial 3 with value: 0.00018433456782738423.\n",
      "[I 2025-01-13 20:42:36,352] Trial 10 finished with value: 0.00876414543017745 and parameters: {'hidden_dim': 256, 'num_layers': 4, 'dropout': 0.19038166469069798, 'learning_rate': 0.009739637219642975}. Best is trial 3 with value: 0.00018433456782738423.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3468920127234377 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:43:01,313] Trial 11 finished with value: 0.00017264093648091975 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.3468920127234377, 'learning_rate': 0.0007974180180084966}. Best is trial 11 with value: 0.00017264093648091975.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3632505901680958 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:43:27,774] Trial 12 finished with value: 0.00015250522681691854 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.3632505901680958, 'learning_rate': 0.0014377984200371087}. Best is trial 12 with value: 0.00015250522681691854.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.36881687807069125 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:43:54,733] Trial 13 finished with value: 0.0001127787254517898 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.36881687807069125, 'learning_rate': 0.0008327749314565197}. Best is trial 13 with value: 0.0001127787254517898.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.38744691222598643 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:44:21,343] Trial 14 finished with value: 0.00027724042593035847 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.38744691222598643, 'learning_rate': 0.0013357040714100919}. Best is trial 13 with value: 0.0001127787254517898.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3766137668095525 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:44:48,605] Trial 15 finished with value: 0.0003231785336869176 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.3766137668095525, 'learning_rate': 0.000675292405046427}. Best is trial 13 with value: 0.0001127787254517898.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.41487908536111456 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:45:12,579] Trial 16 finished with value: 0.00019775666508146307 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.41487908536111456, 'learning_rate': 0.0025695125501262314}. Best is trial 13 with value: 0.0001127787254517898.\n",
      "[I 2025-01-13 20:46:38,936] Trial 17 finished with value: 0.000258015622173182 and parameters: {'hidden_dim': 224, 'num_layers': 3, 'dropout': 0.30201251524282596, 'learning_rate': 0.000489094442708307}. Best is trial 13 with value: 0.0001127787254517898.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.36200128734411 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:46:57,192] Trial 18 finished with value: 0.00015651432874041018 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.36200128734411, 'learning_rate': 0.0024383398142193724}. Best is trial 13 with value: 0.0001127787254517898.\n",
      "[I 2025-01-13 20:48:01,275] Trial 19 finished with value: 0.00027939375220078296 and parameters: {'hidden_dim': 256, 'num_layers': 2, 'dropout': 0.42998212742184383, 'learning_rate': 0.00048299433779713666}. Best is trial 13 with value: 0.0001127787254517898.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23103664350776748 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:48:25,608] Trial 20 finished with value: 0.00011158728342376311 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.23103664350776748, 'learning_rate': 0.0012940273853636116}. Best is trial 20 with value: 0.00011158728342376311.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23937118695745574 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:48:49,980] Trial 21 finished with value: 0.00019792517758270895 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.23937118695745574, 'learning_rate': 0.0011032617913961879}. Best is trial 20 with value: 0.00011158728342376311.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.31479603403657913 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:49:16,932] Trial 22 finished with value: 0.0007278354393995621 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.31479603403657913, 'learning_rate': 0.002118232694898912}. Best is trial 20 with value: 0.00011158728342376311.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2336556552006525 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:49:38,757] Trial 23 finished with value: 0.00010056791771520776 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.2336556552006525, 'learning_rate': 0.003441880245425174}. Best is trial 23 with value: 0.00010056791771520776.\n",
      "[I 2025-01-13 20:50:14,873] Trial 24 finished with value: 0.00019476875273870644 and parameters: {'hidden_dim': 96, 'num_layers': 2, 'dropout': 0.20376154972662475, 'learning_rate': 0.0036387552569926277}. Best is trial 23 with value: 0.00010056791771520776.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2654711666076177 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:50:37,300] Trial 25 finished with value: 8.195560605434531e-05 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.2654711666076177, 'learning_rate': 0.0032424832549874942}. Best is trial 25 with value: 8.195560605434531e-05.\n",
      "[I 2025-01-13 20:51:22,866] Trial 26 finished with value: 0.000273922870374835 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.25808921927629197, 'learning_rate': 0.003667457204877906}. Best is trial 25 with value: 8.195560605434531e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.16502202081418854 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:51:45,428] Trial 27 finished with value: 0.0002166982422667471 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.16502202081418854, 'learning_rate': 0.0036621929297435962}. Best is trial 25 with value: 8.195560605434531e-05.\n",
      "[I 2025-01-13 20:52:42,945] Trial 28 finished with value: 0.000763019075913524 and parameters: {'hidden_dim': 96, 'num_layers': 3, 'dropout': 0.21930328946729927, 'learning_rate': 0.005750309939866058}. Best is trial 25 with value: 8.195560605434531e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.11142059611560115 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:53:07,845] Trial 29 finished with value: 8.010951304723594e-05 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.11142059611560115, 'learning_rate': 0.009706314256981331}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "[I 2025-01-13 20:53:45,710] Trial 30 finished with value: 0.0001155082930133424 and parameters: {'hidden_dim': 96, 'num_layers': 2, 'dropout': 0.10013608638630525, 'learning_rate': 0.008143012967649797}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.17452002866786376 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:54:11,588] Trial 31 finished with value: 8.248119146711278e-05 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.17452002866786376, 'learning_rate': 0.004623221288316541}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.13558344641344117 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:54:36,697] Trial 32 finished with value: 0.00010669861876522191 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.13558344641344117, 'learning_rate': 0.00468053200192489}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.17274992085574553 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:55:00,319] Trial 33 finished with value: 0.0001817016573940319 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.17274992085574553, 'learning_rate': 0.008479350939927384}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1006502222114033 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:55:25,738] Trial 34 finished with value: 0.00010560817083222156 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.1006502222114033, 'learning_rate': 0.007232326278139249}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.27394646211865964 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:55:43,195] Trial 35 finished with value: 0.00017564395238878205 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.27394646211865964, 'learning_rate': 0.0045219920872976065}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "[I 2025-01-13 20:57:30,580] Trial 36 finished with value: 0.00023094775017604908 and parameters: {'hidden_dim': 128, 'num_layers': 4, 'dropout': 0.15539367854538455, 'learning_rate': 0.0029439843050442544}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "[I 2025-01-13 20:58:12,395] Trial 37 finished with value: 0.0001576364891000346 and parameters: {'hidden_dim': 96, 'num_layers': 2, 'dropout': 0.1957306744480051, 'learning_rate': 0.001880119078194181}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.14763819044497148 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:58:40,710] Trial 38 finished with value: 0.00011195099267007953 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.14763819044497148, 'learning_rate': 0.004800072072166838}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "[I 2025-01-13 20:59:15,347] Trial 39 finished with value: 0.0002859061761145395 and parameters: {'hidden_dim': 64, 'num_layers': 2, 'dropout': 0.24988752857562552, 'learning_rate': 0.006461745381106284}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.11559567665355436 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 20:59:44,775] Trial 40 finished with value: 0.00010710686514027078 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.11559567665355436, 'learning_rate': 0.0031343953037851024}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.12353382076942514 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 21:00:10,796] Trial 41 finished with value: 0.0001500932058578738 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.12353382076942514, 'learning_rate': 0.007452984821631155}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.28427811004494613 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 21:00:37,633] Trial 42 finished with value: 0.00011029974583917382 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.28427811004494613, 'learning_rate': 0.009482010784153151}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1010446149660599 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 21:01:01,337] Trial 43 finished with value: 0.0004006717618639496 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.1010446149660599, 'learning_rate': 0.006809837829685159}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1766879404388278 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 21:01:24,137] Trial 44 finished with value: 0.00010997916119363667 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.1766879404388278, 'learning_rate': 0.005072111850978408}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.13783276880551948 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 21:01:49,511] Trial 45 finished with value: 0.0002632796094985679 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.13783276880551948, 'learning_rate': 0.0040573569378046384}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "[I 2025-01-13 21:02:37,561] Trial 46 finished with value: 8.960121241133575e-05 and parameters: {'hidden_dim': 160, 'num_layers': 2, 'dropout': 0.20827377556901538, 'learning_rate': 0.005935596058607539}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "[I 2025-01-13 21:03:23,665] Trial 47 finished with value: 0.0005417472050546414 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.22529238940646848, 'learning_rate': 0.005467807741512812}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "[I 2025-01-13 21:04:42,870] Trial 48 finished with value: 0.0003401002031750977 and parameters: {'hidden_dim': 192, 'num_layers': 3, 'dropout': 0.2133725399623989, 'learning_rate': 0.0031898491976444865}. Best is trial 29 with value: 8.010951304723594e-05.\n",
      "[I 2025-01-13 21:05:34,819] Trial 49 finished with value: 0.00010480656353386372 and parameters: {'hidden_dim': 192, 'num_layers': 2, 'dropout': 0.18504726262490248, 'learning_rate': 0.009611653017518674}. Best is trial 29 with value: 8.010951304723594e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.11142059611560115, 'learning_rate': 0.009706314256981331}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv(\"Book1.csv\")\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "data = data.sort_values(by=\"Date\")\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "numeric_data = data.drop(columns=[\"Date\"])\n",
    "scaled_data = scaler.fit_transform(numeric_data)\n",
    "data[numeric_data.columns] = scaled_data\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_data = data[(data[\"Date\"].dt.year >= 2017) & (data[\"Date\"].dt.year <= 2022)].drop(columns=[\"Date\"]).values\n",
    "val_data = data[data[\"Date\"].dt.year == 2023].drop(columns=[\"Date\"]).values\n",
    "test_data = data[data[\"Date\"].dt.year == 2024].drop(columns=[\"Date\"]).values\n",
    "\n",
    "# Convert data to sequences for time series\n",
    "def create_sequences(data, sequence_length=30):\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequences.append(data[i:i + sequence_length])\n",
    "        targets.append(data[i + sequence_length, 0])  # Assuming target is the first column\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "sequence_length = 30\n",
    "X_train, y_train = create_sequences(train_data, sequence_length)\n",
    "X_val, y_val = create_sequences(val_data, sequence_length)\n",
    "X_test, y_test = create_sequences(test_data, sequence_length)\n",
    "\n",
    "# Prepare data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                        torch.tensor(y_train, dtype=torch.float32)), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                                      torch.tensor(y_val, dtype=torch.float32)), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.MSELoss()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            predictions = model(X_batch).squeeze()\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Define the GRU with Attention model\n",
    "class GRUWithAttention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super(GRUWithAttention, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gru_out, _ = self.gru(x)  # Output shape: (batch_size, seq_length, hidden_dim)\n",
    "        attention_weights = torch.softmax(self.attention(gru_out), dim=1)  # Shape: (batch_size, seq_length, 1)\n",
    "        context_vector = torch.sum(attention_weights * gru_out, dim=1)  # Weighted sum: (batch_size, hidden_dim)\n",
    "        output = self.fc(context_vector)  # Shape: (batch_size, 1)\n",
    "        return output\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 32, 256, step=32)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
    "    num_epochs = 20\n",
    "\n",
    "    # Initialize model\n",
    "    model = GRUWithAttention(X_train.shape[2], hidden_dim, num_layers, dropout)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Training setup\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(X_batch).squeeze()\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate on validation data\n",
    "    val_loss = evaluate_model(model, val_loader, device)\n",
    "    return val_loss\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Output the best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd491d-0f33-4f7a-b7f2-c7b8df2174ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
