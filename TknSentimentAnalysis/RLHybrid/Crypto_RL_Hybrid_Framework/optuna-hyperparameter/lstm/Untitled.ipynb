{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddcdf998-8308-4165-9b1f-0fb839346c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-01-13 21:53:03,450] A new study created in memory with name: no-name-0f06d33c-a0b9-4d69-8882-0175c580632d\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17168\\151290703.py:81: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2025-01-13 21:53:46,716] Trial 0 finished with value: 0.00022190592095615682 and parameters: {'hidden_dim': 128, 'num_layers': 3, 'dropout': 0.2515353798727734, 'learning_rate': 0.00011449245401827655}. Best is trial 0 with value: 0.00022190592095615682.\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17168\\151290703.py:81: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2025-01-13 21:54:16,469] Trial 1 finished with value: 0.0005975991080049425 and parameters: {'hidden_dim': 32, 'num_layers': 3, 'dropout': 0.2667834344815208, 'learning_rate': 0.0024217840003935634}. Best is trial 0 with value: 0.00022190592095615682.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4481340108827244 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 21:54:33,258] Trial 2 finished with value: 5.7729218414434314e-05 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.4481340108827244, 'learning_rate': 0.0020240961276158484}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "[I 2025-01-13 21:55:27,880] Trial 3 finished with value: 0.00017715840063333005 and parameters: {'hidden_dim': 160, 'num_layers': 3, 'dropout': 0.45851308220624276, 'learning_rate': 0.0007330586510048581}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "[I 2025-01-13 21:56:47,643] Trial 4 finished with value: 0.00016882069295124066 and parameters: {'hidden_dim': 192, 'num_layers': 4, 'dropout': 0.31933022558532753, 'learning_rate': 0.00043059176583948213}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.14354129090646178 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 21:57:00,618] Trial 5 finished with value: 8.132647268542893e-05 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.14354129090646178, 'learning_rate': 0.0008023768984178745}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.33902894512733495 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 21:57:18,981] Trial 6 finished with value: 6.966039621726271e-05 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.33902894512733495, 'learning_rate': 0.0005139587856329687}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "[I 2025-01-13 21:58:11,956] Trial 7 finished with value: 0.00017332919643112373 and parameters: {'hidden_dim': 256, 'num_layers': 2, 'dropout': 0.10690221501731273, 'learning_rate': 0.00011124536590469979}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "[I 2025-01-13 21:58:57,737] Trial 8 finished with value: 0.00011576475398297507 and parameters: {'hidden_dim': 224, 'num_layers': 2, 'dropout': 0.3030926432841483, 'learning_rate': 0.005749192750080671}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "[I 2025-01-13 21:59:58,598] Trial 9 finished with value: 0.0002544058105823669 and parameters: {'hidden_dim': 128, 'num_layers': 4, 'dropout': 0.24274584533529997, 'learning_rate': 0.00014982675475407793}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.48770160265043894 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:00:09,320] Trial 10 finished with value: 6.056614537638697e-05 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.48770160265043894, 'learning_rate': 0.002347996572794819}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.48115113550956384 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:00:20,388] Trial 11 finished with value: 0.00016821924046697941 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.48115113550956384, 'learning_rate': 0.002496097650599119}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "[I 2025-01-13 22:00:42,845] Trial 12 finished with value: 0.000168536761934361 and parameters: {'hidden_dim': 64, 'num_layers': 2, 'dropout': 0.40644548010225734, 'learning_rate': 0.0021350586410743243}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4028841866901003 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:00:55,733] Trial 13 finished with value: 6.600832206128292e-05 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.4028841866901003, 'learning_rate': 0.007985097800926511}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.49296745013169685 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:01:05,227] Trial 14 finished with value: 7.907136817018248e-05 and parameters: {'hidden_dim': 32, 'num_layers': 1, 'dropout': 0.49296745013169685, 'learning_rate': 0.0014958961376769823}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "[I 2025-01-13 22:01:29,420] Trial 15 finished with value: 0.00013312302259939977 and parameters: {'hidden_dim': 96, 'num_layers': 2, 'dropout': 0.41533217178295473, 'learning_rate': 0.004367059683689006}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3684616666515557 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:01:46,142] Trial 16 finished with value: 6.344973007799126e-05 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.3684616666515557, 'learning_rate': 0.0033910542030242113}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "[I 2025-01-13 22:02:07,954] Trial 17 finished with value: 0.00017286904436663133 and parameters: {'hidden_dim': 64, 'num_layers': 2, 'dropout': 0.44822021236267806, 'learning_rate': 0.0013530225132747896}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.44233172685891 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:02:21,688] Trial 18 finished with value: 0.0002073288037949665 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.44233172685891, 'learning_rate': 0.00026343461255116924}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "[I 2025-01-13 22:02:47,403] Trial 19 finished with value: 0.0003252346280284903 and parameters: {'hidden_dim': 96, 'num_layers': 2, 'dropout': 0.49939743671490544, 'learning_rate': 0.0010187490292022595}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.361718641462492 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:02:57,342] Trial 20 finished with value: 7.33050626215779e-05 and parameters: {'hidden_dim': 32, 'num_layers': 1, 'dropout': 0.361718641462492, 'learning_rate': 0.008048708936922227}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3741096739669942 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:03:12,895] Trial 21 finished with value: 0.00023945888493802738 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.3741096739669942, 'learning_rate': 0.0035024357106013316}. Best is trial 2 with value: 5.7729218414434314e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.42826469483579593 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:03:30,894] Trial 22 finished with value: 5.2859522012030624e-05 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.42826469483579593, 'learning_rate': 0.0038799357279685875}. Best is trial 22 with value: 5.2859522012030624e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.43552752974162023 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:03:49,026] Trial 23 finished with value: 6.384148318003017e-05 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.43552752974162023, 'learning_rate': 0.001623721040468169}. Best is trial 22 with value: 5.2859522012030624e-05.\n",
      "[I 2025-01-13 22:04:35,141] Trial 24 finished with value: 9.320365345708772e-05 and parameters: {'hidden_dim': 224, 'num_layers': 2, 'dropout': 0.4672622962960977, 'learning_rate': 0.004556973471907053}. Best is trial 22 with value: 5.2859522012030624e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.18583349144276234 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:04:56,335] Trial 25 finished with value: 0.00016368588628459045 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.18583349144276234, 'learning_rate': 0.0026724098875185705}. Best is trial 22 with value: 5.2859522012030624e-05.\n",
      "[I 2025-01-13 22:05:35,663] Trial 26 finished with value: 0.0023169887559065087 and parameters: {'hidden_dim': 192, 'num_layers': 2, 'dropout': 0.39182333599509833, 'learning_rate': 0.009938258455448549}. Best is trial 22 with value: 5.2859522012030624e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.42820466752709013 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:05:58,985] Trial 27 finished with value: 5.233818443560846e-05 and parameters: {'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.42820466752709013, 'learning_rate': 0.0018529598174487406}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "[I 2025-01-13 22:07:24,195] Trial 28 finished with value: 8.13210954220267e-05 and parameters: {'hidden_dim': 256, 'num_layers': 3, 'dropout': 0.4275790826908543, 'learning_rate': 0.0011560263303402115}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35029948505533925 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:07:47,936] Trial 29 finished with value: 5.452803055628795e-05 and parameters: {'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.35029948505533925, 'learning_rate': 0.005466527180092643}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "[I 2025-01-13 22:08:40,930] Trial 30 finished with value: 6.32869796390878e-05 and parameters: {'hidden_dim': 256, 'num_layers': 2, 'dropout': 0.26975234201369147, 'learning_rate': 0.006219321047385513}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3358654991963852 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:09:02,328] Trial 31 finished with value: 5.373585885205433e-05 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.3358654991963852, 'learning_rate': 0.0017440703698243954}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35174545708902877 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:09:23,461] Trial 32 finished with value: 0.00026275869194333524 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.35174545708902877, 'learning_rate': 0.0032421630654193407}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3274733172062179 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:09:47,151] Trial 33 finished with value: 5.8289512956186876e-05 and parameters: {'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.3274733172062179, 'learning_rate': 0.004636912337677646}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.24019081376591883 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:10:08,298] Trial 34 finished with value: 5.8079380489123814e-05 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.24019081376591883, 'learning_rate': 0.0019368795673223875}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "[I 2025-01-13 22:11:30,946] Trial 35 finished with value: 8.12992948340252e-05 and parameters: {'hidden_dim': 256, 'num_layers': 3, 'dropout': 0.2926978309607161, 'learning_rate': 0.006293455925033862}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.29700631274661404 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:11:52,213] Trial 36 finished with value: 6.158263237342577e-05 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.29700631274661404, 'learning_rate': 0.000742282289084896}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "[I 2025-01-13 22:13:12,829] Trial 37 finished with value: 0.00024869407339296726 and parameters: {'hidden_dim': 192, 'num_layers': 4, 'dropout': 0.39544233570050114, 'learning_rate': 0.0031204789283070873}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3409527783579119 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:13:36,460] Trial 38 finished with value: 0.00013930662283779714 and parameters: {'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.3409527783579119, 'learning_rate': 0.0017710834114110553}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "[I 2025-01-13 22:14:22,485] Trial 39 finished with value: 0.00012995300825092602 and parameters: {'hidden_dim': 224, 'num_layers': 2, 'dropout': 0.37906281571604755, 'learning_rate': 0.0012477047240153048}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4619782029528269 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:14:40,573] Trial 40 finished with value: 5.88996428467164e-05 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.4619782029528269, 'learning_rate': 0.004111877964933741}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4260934317479377 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:14:55,060] Trial 41 finished with value: 7.77749525944025e-05 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.4260934317479377, 'learning_rate': 0.0009678672054718591}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.31961406150474747 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:15:11,210] Trial 42 finished with value: 7.13661310411143e-05 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.31961406150474747, 'learning_rate': 0.0027197172391412025}. Best is trial 27 with value: 5.233818443560846e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4678956205065841 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:15:34,332] Trial 43 finished with value: 4.835756590182427e-05 and parameters: {'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.4678956205065841, 'learning_rate': 0.002168276979669592}. Best is trial 43 with value: 4.835756590182427e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.47412647116438605 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:15:58,499] Trial 44 finished with value: 6.637682583294173e-05 and parameters: {'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.47412647116438605, 'learning_rate': 0.0005412634332349652}. Best is trial 43 with value: 4.835756590182427e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4538220280349208 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:16:21,804] Trial 45 finished with value: 0.00010283624578732997 and parameters: {'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.4538220280349208, 'learning_rate': 0.005385177221624532}. Best is trial 43 with value: 4.835756590182427e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2703630948189058 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:16:42,929] Trial 46 finished with value: 7.67800857746889e-05 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.2703630948189058, 'learning_rate': 0.0021092572487817615}. Best is trial 43 with value: 4.835756590182427e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.22304725643597206 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:17:07,177] Trial 47 finished with value: 5.5598576926224105e-05 and parameters: {'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.22304725643597206, 'learning_rate': 0.0015719697354964676}. Best is trial 43 with value: 4.835756590182427e-05.\n",
      "[I 2025-01-13 22:17:53,091] Trial 48 finished with value: 8.745841842028312e-05 and parameters: {'hidden_dim': 224, 'num_layers': 2, 'dropout': 0.41734917006701455, 'learning_rate': 0.0025242178817201813}. Best is trial 43 with value: 4.835756590182427e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3878043054545356 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:18:16,315] Trial 49 finished with value: 0.00017506799089129675 and parameters: {'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.3878043054545356, 'learning_rate': 0.003909887806574998}. Best is trial 43 with value: 4.835756590182427e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.4678956205065841, 'learning_rate': 0.002168276979669592}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv(\"Book1.csv\")\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "data = data.sort_values(by=\"Date\")\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "numeric_data = data.drop(columns=[\"Date\"])\n",
    "scaled_data = scaler.fit_transform(numeric_data)\n",
    "data[numeric_data.columns] = scaled_data\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_data = data[(data[\"Date\"].dt.year >= 2017) & (data[\"Date\"].dt.year <= 2022)].drop(columns=[\"Date\"]).values\n",
    "val_data = data[data[\"Date\"].dt.year == 2023].drop(columns=[\"Date\"]).values\n",
    "test_data = data[data[\"Date\"].dt.year == 2024].drop(columns=[\"Date\"]).values\n",
    "\n",
    "# Convert data to sequences for time series\n",
    "def create_sequences(data, sequence_length=30):\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequences.append(data[i:i + sequence_length])\n",
    "        targets.append(data[i + sequence_length, 0])  # Assuming target is the first column\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "sequence_length = 30\n",
    "X_train, y_train = create_sequences(train_data, sequence_length)\n",
    "X_val, y_val = create_sequences(val_data, sequence_length)\n",
    "X_test, y_test = create_sequences(test_data, sequence_length)\n",
    "\n",
    "# Prepare data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                        torch.tensor(y_train, dtype=torch.float32)), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                                      torch.tensor(y_val, dtype=torch.float32)), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.MSELoss()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            predictions = model(X_batch).squeeze()\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)  # Output shape: (batch_size, seq_length, hidden_dim)\n",
    "        output = self.fc(lstm_out[:, -1, :])  # Use the last hidden state for prediction\n",
    "        return output\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 32, 256, step=32)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
    "    num_epochs = 20\n",
    "\n",
    "    # Initialize model\n",
    "    model = LSTMModel(X_train.shape[2], hidden_dim, num_layers, dropout)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Training setup\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(X_batch).squeeze()\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate on validation data\n",
    "    val_loss = evaluate_model(model, val_loader, device)\n",
    "    return val_loss\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Output the best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b2f51-f2d3-48ba-9934-4e808fd14d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
