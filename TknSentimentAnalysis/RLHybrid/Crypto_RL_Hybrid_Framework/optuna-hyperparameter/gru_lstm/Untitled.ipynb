{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d72edb-0a10-4c28-bdad-4c7b122f511b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-01-13 22:21:02,123] A new study created in memory with name: no-name-558bb79f-5f62-4a96-b43c-2948fdd37861\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14476\\2368778895.py:83: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25396884283986365 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:21:46,894] Trial 0 finished with value: 6.372703931199133e-05 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.25396884283986365, 'learning_rate': 0.004171675023498139}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14476\\2368778895.py:83: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2025-01-13 22:23:51,927] Trial 1 finished with value: 0.00015245500551166268 and parameters: {'hidden_dim': 160, 'num_layers': 3, 'dropout': 0.16077566204218413, 'learning_rate': 0.00019262642035257823}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4373986404387773 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:24:18,028] Trial 2 finished with value: 6.416985293485182e-05 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.4373986404387773, 'learning_rate': 0.0005726586489207707}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "[I 2025-01-13 22:25:35,102] Trial 3 finished with value: 0.0003016148025794378 and parameters: {'hidden_dim': 64, 'num_layers': 3, 'dropout': 0.2732902715550117, 'learning_rate': 0.0002167055812593669}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.206751161049315 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:26:11,132] Trial 4 finished with value: 0.00010565999599004334 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.206751161049315, 'learning_rate': 0.004053422519214918}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "[I 2025-01-13 22:29:49,100] Trial 5 finished with value: 0.00030560570435640824 and parameters: {'hidden_dim': 224, 'num_layers': 4, 'dropout': 0.32302654149891885, 'learning_rate': 0.0002607962971889375}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2178010780895212 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:30:18,960] Trial 6 finished with value: 0.0002070180324318988 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.2178010780895212, 'learning_rate': 0.00016654909818923465}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "[I 2025-01-13 22:31:37,429] Trial 7 finished with value: 0.0002713657980745087 and parameters: {'hidden_dim': 64, 'num_layers': 3, 'dropout': 0.3247335612651593, 'learning_rate': 0.00025759130969978556}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "[I 2025-01-13 22:33:10,322] Trial 8 finished with value: 0.0003323467337230051 and parameters: {'hidden_dim': 192, 'num_layers': 2, 'dropout': 0.2919143219328409, 'learning_rate': 0.0020653554549952503}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "[I 2025-01-13 22:36:01,082] Trial 9 finished with value: 0.0014078322088938546 and parameters: {'hidden_dim': 160, 'num_layers': 4, 'dropout': 0.3290817232749871, 'learning_rate': 0.0029338044583488926}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "[I 2025-01-13 22:39:33,966] Trial 10 finished with value: 0.008600845170969313 and parameters: {'hidden_dim': 256, 'num_layers': 2, 'dropout': 0.47945362305308353, 'learning_rate': 0.009105215724647672}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4294267980582165 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:39:50,138] Trial 11 finished with value: 8.44326595225456e-05 and parameters: {'hidden_dim': 32, 'num_layers': 1, 'dropout': 0.4294267980582165, 'learning_rate': 0.0014889969766350905}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "[I 2025-01-13 22:41:05,975] Trial 12 finished with value: 0.0004345397828728892 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.403533293318596, 'learning_rate': 0.0007646869621178412}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.37860248663752516 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:41:52,529] Trial 13 finished with value: 7.012576778916727e-05 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.37860248663752516, 'learning_rate': 0.0006126810859235189}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4990895738339367 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:42:09,452] Trial 14 finished with value: 6.741423964161764e-05 and parameters: {'hidden_dim': 32, 'num_layers': 1, 'dropout': 0.4990895738339367, 'learning_rate': 0.007139601115745415}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "[I 2025-01-13 22:44:15,420] Trial 15 finished with value: 6.697045517450368e-05 and parameters: {'hidden_dim': 256, 'num_layers': 2, 'dropout': 0.24354899644609115, 'learning_rate': 0.0005344646035347932}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.11393451036229915 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:44:45,996] Trial 16 finished with value: 6.443426404571669e-05 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.11393451036229915, 'learning_rate': 0.0013294676279669976}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "[I 2025-01-13 22:46:18,864] Trial 17 finished with value: 9.694995804404078e-05 and parameters: {'hidden_dim': 192, 'num_layers': 2, 'dropout': 0.3819343736243668, 'learning_rate': 0.00045302525404047363}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4548272124692518 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:46:48,622] Trial 18 finished with value: 8.083314771118404e-05 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.4548272124692518, 'learning_rate': 0.005233042769727933}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "[I 2025-01-13 22:48:36,310] Trial 19 finished with value: 8.635006551313299e-05 and parameters: {'hidden_dim': 224, 'num_layers': 2, 'dropout': 0.1728246584118818, 'learning_rate': 0.0010448458675104807}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.36107182161849793 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:49:02,260] Trial 20 finished with value: 7.153514194545674e-05 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.36107182161849793, 'learning_rate': 0.0024004736169848896}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.15247172053579944 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:49:32,540] Trial 21 finished with value: 0.00014777540425050327 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.15247172053579944, 'learning_rate': 0.0011771789254266466}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.10608641550812062 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:50:09,315] Trial 22 finished with value: 6.519453117190014e-05 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.10608641550812062, 'learning_rate': 0.00039269169685139454}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.12693979969479205 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:50:39,667] Trial 23 finished with value: 0.00010537988815816458 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.12693979969479205, 'learning_rate': 0.00011400578979518225}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "[I 2025-01-13 22:51:36,891] Trial 24 finished with value: 8.173270676210946e-05 and parameters: {'hidden_dim': 64, 'num_layers': 2, 'dropout': 0.2641698669888114, 'learning_rate': 0.001877514301699538}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.18438226154473086 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:52:19,222] Trial 25 finished with value: 0.0005180628861787475 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.18438226154473086, 'learning_rate': 0.003641112674472722}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "[I 2025-01-13 22:52:53,527] Trial 26 finished with value: 0.00022905570883515546 and parameters: {'hidden_dim': 32, 'num_layers': 2, 'dropout': 0.21808585200174413, 'learning_rate': 0.0007760796498949141}. Best is trial 0 with value: 6.372703931199133e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.42181140317553034 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:53:48,287] Trial 27 finished with value: 5.506902380147949e-05 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.42181140317553034, 'learning_rate': 0.0014520365477082432}. Best is trial 27 with value: 5.506902380147949e-05.\n",
      "[I 2025-01-13 22:56:29,360] Trial 28 finished with value: 0.0005425148291661488 and parameters: {'hidden_dim': 224, 'num_layers': 3, 'dropout': 0.4526197446521306, 'learning_rate': 0.005289445126190972}. Best is trial 27 with value: 5.506902380147949e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.41910098299430215 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:57:11,027] Trial 29 finished with value: 6.902990406326188e-05 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.41910098299430215, 'learning_rate': 0.0003367268865442127}. Best is trial 27 with value: 5.506902380147949e-05.\n",
      "[I 2025-01-13 22:58:57,657] Trial 30 finished with value: 7.527517498767173e-05 and parameters: {'hidden_dim': 224, 'num_layers': 2, 'dropout': 0.35147423460732863, 'learning_rate': 0.0008201555404532736}. Best is trial 27 with value: 5.506902380147949e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.45384152715882803 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 22:59:43,528] Trial 31 finished with value: 5.611913184111472e-05 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.45384152715882803, 'learning_rate': 0.001492435805795533}. Best is trial 27 with value: 5.506902380147949e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.45512659178749665 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 23:00:29,119] Trial 32 finished with value: 0.0001918322695101696 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.45512659178749665, 'learning_rate': 0.0016556800344168978}. Best is trial 27 with value: 5.506902380147949e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4284202014685451 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 23:01:14,691] Trial 33 finished with value: 0.00017678810664537278 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.4284202014685451, 'learning_rate': 0.003103166587829584}. Best is trial 27 with value: 5.506902380147949e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4091906648367804 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 23:02:07,854] Trial 34 finished with value: 9.437292332718657e-05 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.4091906648367804, 'learning_rate': 0.002319250498592763}. Best is trial 27 with value: 5.506902380147949e-05.\n",
      "[I 2025-01-13 23:06:22,686] Trial 35 finished with value: 0.00024055011718618599 and parameters: {'hidden_dim': 256, 'num_layers': 4, 'dropout': 0.4783281963514235, 'learning_rate': 0.0009630855001648863}. Best is trial 27 with value: 5.506902380147949e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.289004183125925 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 23:07:04,265] Trial 36 finished with value: 0.0004338056089843369 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.289004183125925, 'learning_rate': 0.00473478581775084}. Best is trial 27 with value: 5.506902380147949e-05.\n",
      "[I 2025-01-13 23:09:25,620] Trial 37 finished with value: 0.00026041935780085623 and parameters: {'hidden_dim': 192, 'num_layers': 3, 'dropout': 0.4960525865155561, 'learning_rate': 0.0006099373320418873}. Best is trial 27 with value: 5.506902380147949e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.39357366644561154 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 23:10:18,173] Trial 38 finished with value: 5.4912799565830604e-05 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.39357366644561154, 'learning_rate': 0.0003010755640891354}. Best is trial 38 with value: 5.4912799565830604e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3793243408812049 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 23:11:12,791] Trial 39 finished with value: 8.82982706323012e-05 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.3793243408812049, 'learning_rate': 0.00014171484104455491}. Best is trial 38 with value: 5.4912799565830604e-05.\n",
      "[I 2025-01-13 23:13:19,184] Trial 40 finished with value: 0.0001445491252525244 and parameters: {'hidden_dim': 256, 'num_layers': 2, 'dropout': 0.30855902126350226, 'learning_rate': 0.0002136739067974155}. Best is trial 38 with value: 5.4912799565830604e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4451369460610756 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 23:14:05,136] Trial 41 finished with value: 0.00012964753213137473 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.4451369460610756, 'learning_rate': 0.00034720023143435387}. Best is trial 38 with value: 5.4912799565830604e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.39746101807709 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 23:14:57,821] Trial 42 finished with value: 6.95772614562884e-05 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.39746101807709, 'learning_rate': 0.00026336238065849095}. Best is trial 38 with value: 5.4912799565830604e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.34223763439464433 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 23:15:50,281] Trial 43 finished with value: 0.0003060348323990845 and parameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.34223763439464433, 'learning_rate': 0.0027989821517872813}. Best is trial 38 with value: 5.4912799565830604e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4737913995707665 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 23:16:32,516] Trial 44 finished with value: 0.00011450465833397836 and parameters: {'hidden_dim': 160, 'num_layers': 1, 'dropout': 0.4737913995707665, 'learning_rate': 0.00992488236711899}. Best is trial 38 with value: 5.4912799565830604e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4383552662606986 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 23:17:08,117] Trial 45 finished with value: 8.978346092838116e-05 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.4383552662606986, 'learning_rate': 0.0068704066988984555}. Best is trial 38 with value: 5.4912799565830604e-05.\n",
      "[I 2025-01-13 23:19:13,659] Trial 46 finished with value: 0.00040521174907387996 and parameters: {'hidden_dim': 256, 'num_layers': 2, 'dropout': 0.2604765111075128, 'learning_rate': 0.0005493608164163575}. Best is trial 38 with value: 5.4912799565830604e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23107470725844725 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 23:19:59,605] Trial 47 finished with value: 5.5172167941980824e-05 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.23107470725844725, 'learning_rate': 0.001386257291449833}. Best is trial 38 with value: 5.4912799565830604e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23415174800891364 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 23:20:45,187] Trial 48 finished with value: 5.6193097241868436e-05 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.23415174800891364, 'learning_rate': 0.0014413684407858166}. Best is trial 38 with value: 5.4912799565830604e-05.\n",
      "C:\\Users\\User\\anaconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23732438351710852 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-01-13 23:21:30,919] Trial 49 finished with value: 0.00024834277362308717 and parameters: {'hidden_dim': 192, 'num_layers': 1, 'dropout': 0.23732438351710852, 'learning_rate': 0.0013964830262784434}. Best is trial 38 with value: 5.4912799565830604e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'hidden_dim': 224, 'num_layers': 1, 'dropout': 0.39357366644561154, 'learning_rate': 0.0003010755640891354}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv(\"Book1.csv\")\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "data = data.sort_values(by=\"Date\")\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "numeric_data = data.drop(columns=[\"Date\"])\n",
    "scaled_data = scaler.fit_transform(numeric_data)\n",
    "data[numeric_data.columns] = scaled_data\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_data = data[(data[\"Date\"].dt.year >= 2017) & (data[\"Date\"].dt.year <= 2022)].drop(columns=[\"Date\"]).values\n",
    "val_data = data[data[\"Date\"].dt.year == 2023].drop(columns=[\"Date\"]).values\n",
    "test_data = data[data[\"Date\"].dt.year == 2024].drop(columns=[\"Date\"]).values\n",
    "\n",
    "# Convert data to sequences for time series\n",
    "def create_sequences(data, sequence_length=30):\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequences.append(data[i:i + sequence_length])\n",
    "        targets.append(data[i + sequence_length, 0])  # Assuming target is the first column\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "sequence_length = 30\n",
    "X_train, y_train = create_sequences(train_data, sequence_length)\n",
    "X_val, y_val = create_sequences(val_data, sequence_length)\n",
    "X_test, y_test = create_sequences(test_data, sequence_length)\n",
    "\n",
    "# Prepare data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                        torch.tensor(y_train, dtype=torch.float32)), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                                      torch.tensor(y_val, dtype=torch.float32)), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.MSELoss()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            predictions = model(X_batch).squeeze()\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Define the hybrid GRU-LSTM model\n",
    "class GRULSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super(GRULSTMModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gru_out, _ = self.gru(x)  # GRU output\n",
    "        lstm_out, _ = self.lstm(gru_out)  # LSTM takes GRU output as input\n",
    "        output = self.fc(lstm_out[:, -1, :])  # Use the last hidden state for prediction\n",
    "        return output\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 32, 256, step=32)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
    "    num_epochs = 20\n",
    "\n",
    "    # Initialize model\n",
    "    model = GRULSTMModel(X_train.shape[2], hidden_dim, num_layers, dropout)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Training setup\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(X_batch).squeeze()\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate on validation data\n",
    "    val_loss = evaluate_model(model, val_loader, device)\n",
    "    return val_loss\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Output the best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e643d17-49de-4cf3-b4ce-806281f84c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
